{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed59e13f-6285-4900-b4d4-30e128a99f66",
   "metadata": {},
   "source": [
    "# Суммаризатор видео"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1d06f2-30ee-459f-84e5-999a36afd3a2",
   "metadata": {},
   "source": [
    "## 0. Устанавливаем необходимые зависимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2285e671-66db-4346-a27e-52b37fffe3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yt-dlp in ./venv_jupyter/lib/python3.12/site-packages (2025.11.12)\n",
      "Requirement already satisfied: moviepy in ./venv_jupyter/lib/python3.12/site-packages (2.2.1)\n",
      "Requirement already satisfied: ffmpeg-python in ./venv_jupyter/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: faster-whisper in ./venv_jupyter/lib/python3.12/site-packages (1.2.1)\n",
      "Requirement already satisfied: torch in ./venv_jupyter/lib/python3.12/site-packages (2.9.1)\n",
      "Requirement already satisfied: transformers[sentencepiece] in ./venv_jupyter/lib/python3.12/site-packages (4.57.1)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in ./venv_jupyter/lib/python3.12/site-packages (from moviepy) (5.2.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in ./venv_jupyter/lib/python3.12/site-packages (from moviepy) (2.37.2)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in ./venv_jupyter/lib/python3.12/site-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in ./venv_jupyter/lib/python3.12/site-packages (from moviepy) (2.3.4)\n",
      "Requirement already satisfied: proglog<=1.0.0 in ./venv_jupyter/lib/python3.12/site-packages (from moviepy) (0.1.12)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in ./venv_jupyter/lib/python3.12/site-packages (from moviepy) (1.2.1)\n",
      "Requirement already satisfied: pillow<12.0,>=9.2.0 in ./venv_jupyter/lib/python3.12/site-packages (from moviepy) (11.3.0)\n",
      "Requirement already satisfied: future in ./venv_jupyter/lib/python3.12/site-packages (from ffmpeg-python) (1.0.0)\n",
      "Requirement already satisfied: filelock in ./venv_jupyter/lib/python3.12/site-packages (from transformers[sentencepiece]) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./venv_jupyter/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv_jupyter/lib/python3.12/site-packages (from transformers[sentencepiece]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv_jupyter/lib/python3.12/site-packages (from transformers[sentencepiece]) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv_jupyter/lib/python3.12/site-packages (from transformers[sentencepiece]) (2025.11.3)\n",
      "Requirement already satisfied: requests in ./venv_jupyter/lib/python3.12/site-packages (from transformers[sentencepiece]) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./venv_jupyter/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./venv_jupyter/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv_jupyter/lib/python3.12/site-packages (from transformers[sentencepiece]) (4.67.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in ./venv_jupyter/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.2.1)\n",
      "Requirement already satisfied: protobuf in ./venv_jupyter/lib/python3.12/site-packages (from transformers[sentencepiece]) (6.33.1)\n",
      "Requirement already satisfied: ctranslate2<5,>=4.0 in ./venv_jupyter/lib/python3.12/site-packages (from faster-whisper) (4.6.1)\n",
      "Requirement already satisfied: onnxruntime<2,>=1.14 in ./venv_jupyter/lib/python3.12/site-packages (from faster-whisper) (1.23.2)\n",
      "Requirement already satisfied: av>=11 in ./venv_jupyter/lib/python3.12/site-packages (from faster-whisper) (16.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./venv_jupyter/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./venv_jupyter/lib/python3.12/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./venv_jupyter/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (1.2.0)\n",
      "Requirement already satisfied: coloredlogs in ./venv_jupyter/lib/python3.12/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./venv_jupyter/lib/python3.12/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.9.23)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv_jupyter/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv_jupyter/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv_jupyter/lib/python3.12/site-packages (from requests->transformers[sentencepiece]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv_jupyter/lib/python3.12/site-packages (from requests->transformers[sentencepiece]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv_jupyter/lib/python3.12/site-packages (from requests->transformers[sentencepiece]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv_jupyter/lib/python3.12/site-packages (from requests->transformers[sentencepiece]) (2025.10.5)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./venv_jupyter/lib/python3.12/site-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install yt-dlp moviepy ffmpeg-python transformers[sentencepiece] faster-whisper torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c361ea19-92d0-4b3c-afc2-d876358e4459",
   "metadata": {},
   "source": [
    "## 1. Скачиваем видео по ссылке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1417e945-cbcc-4d94-8c57-82b2613a15ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yt_dlp as ytdl\n",
    "\n",
    "def download_video(url: str, out_dir: str = \"downloads\") -> Path:\n",
    "    out_dir_p = Path(out_dir)\n",
    "    out_dir_p.mkdir(parents=True, exist_ok=True)\n",
    "    ydl_opts = {\n",
    "        'outtmpl': str(out_dir_p / '%(title)s.%(ext)s'),\n",
    "        'format': 'bestvideo+bestaudio/best',\n",
    "        'noplaylist': True,\n",
    "        'quiet': True,\n",
    "        'no_warnings': True,\n",
    "    }\n",
    "    with ytdl.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(url, download=True)\n",
    "        # инфа содержит 'title' и 'ext'\n",
    "        filename = ydl.prepare_filename(info)\n",
    "    return Path(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4345a607-561b-409c-a87f-178ad85786ad",
   "metadata": {},
   "source": [
    "## 2. Извлечение аудио"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12745ec7-bfd3-410e-9996-b004058c9d0d",
   "metadata": {},
   "source": [
    "## 3. Траскрибация аудио"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f817530-ba35-4d85-acb3-631659f09503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ТЕСТОВЫЙ ТРАНСКРИБИРОВАННЫЙ ТЕКСТ:\n",
      "==================================================\n",
      "\n",
      "В этом видео рассказывается о красоте математики. Автор объясняет, что математика - это не просто сухие цифры и формулы, \n",
      "а удивительный язык, описывающий вселенную. Рассматривается пример числа Пи - бесконечной десятичной дроби, \n",
      "которая встречается в самых неожиданных местах: от геометрии круга до квантовой физики. \n",
      "Особое внимание уделяется формуле Эйлера, которая элегантно связывает пять фундаментальных математических констант. \n",
      "Математика учит логическому мышлению, помогает находить закономерности и решать сложные проблемы. \n",
      "Каждая доказанная теорема - это маленькое открытие, приближающее нас к пониманию мира. \n",
      "Автор призывает не бояться математики, подчеркивая ее красоту и увлекательность.\n",
      "Математические концепции могут казаться сложными на первый взгляд, но при глубоком изучении \n",
      "открывают свою внутреннюю гармонию и логическую завершенность. Именно эта гармония \n",
      "и делает математику по-настоящему красивой наукой, которая помогает нам понимать \n",
      "законы природы и создавать новые технологии.\n",
      "\n",
      "==================================================\n",
      "Длина текста: 1010 символов\n"
     ]
    }
   ],
   "source": [
    "# Пропускаем скачивание видео, извлечение аудио и транскрибацию\n",
    "# Используем готовый тестовый текст для суммаризации\n",
    "\n",
    "text = \"\"\"\n",
    "В этом видео рассказывается о красоте математики. Автор объясняет, что математика - это не просто сухие цифры и формулы, \n",
    "а удивительный язык, описывающий вселенную. Рассматривается пример числа Пи - бесконечной десятичной дроби, \n",
    "которая встречается в самых неожиданных местах: от геометрии круга до квантовой физики. \n",
    "Особое внимание уделяется формуле Эйлера, которая элегантно связывает пять фундаментальных математических констант. \n",
    "Математика учит логическому мышлению, помогает находить закономерности и решать сложные проблемы. \n",
    "Каждая доказанная теорема - это маленькое открытие, приближающее нас к пониманию мира. \n",
    "Автор призывает не бояться математики, подчеркивая ее красоту и увлекательность.\n",
    "Математические концепции могут казаться сложными на первый взгляд, но при глубоком изучении \n",
    "открывают свою внутреннюю гармонию и логическую завершенность. Именно эта гармония \n",
    "и делает математику по-настоящему красивой наукой, которая помогает нам понимать \n",
    "законы природы и создавать новые технологии.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ТЕСТОВЫЙ ТРАНСКРИБИРОВАННЫЙ ТЕКСТ:\")\n",
    "print(\"=\" * 50)\n",
    "print(text)\n",
    "print(\"=\" * 50)\n",
    "print(f\"Длина текста: {len(text)} символов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab9fa96-1357-4b12-a837-dcc49af2f59d",
   "metadata": {},
   "source": [
    "## 4. Суммвризация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da13b74-c854-4684-89e3-5fdeed10a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, max_chars: int = 3000):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + max_chars\n",
    "        chunks.append(text[start:end])\n",
    "        start = end\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6b67b9a-385e-418e-88f6-1dc6d7f18ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def summarize_text(text: str, model_name: str, max_chunk_chars: int = 3000) -> str:\n",
    "    summarizer = pipeline('summarization', model=model_name, truncation=True)\n",
    "    chunks = chunk_text(text, max_chars=max_chunk_chars)\n",
    "    summaries = []\n",
    "    for i, ch in enumerate(chunks):\n",
    "        res = summarizer(ch, max_length=200, min_length=30, do_sample=False)\n",
    "        summaries.append(res[0]['summary_text'])\n",
    "\n",
    "    if len(summaries) > 1:\n",
    "        joined = ' '.join(summaries)\n",
    "        res2 = summarizer(joined, max_length=250, min_length=50, do_sample=False)\n",
    "        return res2[0]['summary_text']\n",
    "    else:\n",
    "        return summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "276df193-154a-4895-b480-d9d82948509a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\xa0\\xa0- \\xa0-\\xa0\\xa0\\xa0‘‘Математика’ - \\xa0–\\xa0- ‘.’ – \\xa0‚аганная теоре’, ‘.-‘-“” –\\xa0“\\xa0” - “\\xa0-” ‘- “-\\u2009”:\\xa0\\u2009гера.гифра, \\u2009Љ’: “.-” \\xa0\"- \\u2009\\u2009\\xa0’-  \\u2009-  \\xa0Љ-’s ‘\\u2009- ”- ’'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_text(text, 'sshleifer/distilbart-cnn-12-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9744143-72d5-4513-9d3d-7468e0d5cc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В этом видео рассказывается о красоте математики. Автор объясняет, что математика - это не просто сухие цифры и формулы, \n",
      "а удивительный язык, описывающий вселенную. Рассматривается пример числа Пи - бесконечной десятичной дроби, \n",
      "которая встречается в самых неожиданных местах: от геометрии круга до квантовой физики. Особое внимание уделяется формуле Эйлера, которая элегантно связывает пять фундаментальных математических констант. Автор призывает не бояться математики, подчеркивая ее красоту и увлекательность.</s>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, T5ForConditionalGeneration \n",
    "tokenizer = GPT2Tokenizer.from_pretrained('RussianNLP/FRED-T5-Summarizer',eos_token='</s>')\n",
    "model = T5ForConditionalGeneration.from_pretrained('RussianNLP/FRED-T5-Summarizer')\n",
    "device='cpu'\n",
    "model.to(device)\n",
    "\n",
    "#input_text='<LM> Сократи текст.\\n В деревне, затерянной среди зелёных холмов, жил старик по имени Иван. Его жизнь протекала медленно и размеренно. Каждое утро Иван выходил на поля, чтобы заботиться о своём скромном участке земли. Он выращивал картофель и морковь, которые были его главным источником пищи. Вечера старик проводил у камина, читая книги и вспоминая молодость. Жизнь в деревне была тяжёлая, но Иван находил в ней простые радости.'\n",
    "input_ids=torch.tensor([tokenizer.encode(text)]).to(device)\n",
    "outputs=model.generate(input_ids,eos_token_id=tokenizer.eos_token_id,\n",
    "                    num_beams=5,\n",
    "                    min_new_tokens=17,\n",
    "                    max_new_tokens=200,\n",
    "                    do_sample=True,\n",
    "                    no_repeat_ngram_size=4,\n",
    "                    top_p=0.9)\n",
    "print(tokenizer.decode(outputs[0][1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6217a15-849c-4333-9e24-d9f3099cb373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Огромное удовольствие — в этой видео приводит сюда мастер-класс «Декорийные триугольники»\n",
      "В этом видео выставка немного посвящена вопросам уроков. На телевидении представление отряда из научных взглядов «\n",
      "Смотрите видео, рассказывающие об красоте математики. Программа наносит впечатление про любую науку\n",
      "На видео обзора показаны несколько способов выяснить красоту математики.\n",
      "В этом видео рассказывается, какие имеет свой внутренний язык. На следующий день он показывает картину классификации «М\n",
      "Какую глубокое изучение изучают математику?\n",
      "В этом видео рассказывается о красоте математики.\n",
      "Затем и покажу подробное видео в поддержку исторической науке, создавающей новую технологию.\n",
      "Итого же можно выяснить в продемонстрированном видео.\n",
      "С ученым издания проходит тематическое видео, посвященное теме математики. В конце автор рассказывает свою удивительную поэтике\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"cointegrated/rut5-base-absum\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"cointegrated/rut5-base-absum\")\n",
    "\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    hypotheses = model.generate(\n",
    "        **inputs, \n",
    "        do_sample=True, top_p=0.95, num_return_sequences=10, \n",
    "        repetition_penalty=2.5,\n",
    "        max_length=32,\n",
    "    )\n",
    "for h in hypotheses:\n",
    "    print(tokenizer.decode(h, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93082a97-2d10-4cf1-92dd-0e5bcfefcbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== НОВАЯ МОДЕЛЬ 1: IlyaGusev/rut5_base_sum_gazeta ===\n",
      "Загрузка модели...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обрабатываю чанк 1/2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 120, but your input_length is only 61. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обрабатываю чанк 2/2...\n",
      "\n",
      "==================================================\n",
      "РЕЗУЛЬТАТ СУММАРИЗАЦИИ:\n",
      "==================================================\n",
      "В сети появилось видео, на котором автор рассказывает о красоте математики. Автор объясняет, что математика - это не просто сухие цифры и формулы, а удивительный язык, описывающий вселенную. Математика является красивой наукой, которая помогает нам понимать законы природы и создавать новые технологии. Математика является красивой наукой, которая помогает нам понимать законы природы и создавать новые технологии.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# НОВАЯ МОДЕЛЬ 1: IlyaGusev/rut5_base_sum_gazeta\n",
    "print(\"=== НОВАЯ МОДЕЛЬ 1: IlyaGusev/rut5_base_sum_gazeta ===\")\n",
    "print(\"Загрузка модели...\")\n",
    "\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "    \n",
    "    summarizer = pipeline(\"summarization\", model=\"IlyaGusev/rut5_base_sum_gazeta\")\n",
    "    \n",
    "    # Разбиваем текст на части\n",
    "    chunks = chunk_text(text, max_chars=800)\n",
    "    summaries = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Обрабатываю чанк {i+1}/{len(chunks)}...\")\n",
    "        result = summarizer(chunk, max_length=120, min_length=40, do_sample=False)\n",
    "        summaries.append(result[0]['summary_text'])\n",
    "    \n",
    "    final_summary = \" \".join(summaries)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"РЕЗУЛЬТАТ СУММАРИЗАЦИИ:\")\n",
    "    print(\"=\"*50)\n",
    "    print(final_summary)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Ошибка: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae2cb600-e736-4aef-b7eb-98417cb596f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== НОВАЯ МОДЕЛЬ 2: sberbank-ai/ruT5-large ===\n",
      "Загрузка модели...\n",
      "Генерирую суммаризацию...\n",
      "\n",
      "==================================================\n",
      "РЕЗУЛЬТАТ СУММАРИЗАЦИИ:\n",
      "==================================================\n",
      "summarize: summarize: summarize: summarize: summarize: summarize: summarize:.......\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# НОВАЯ МОДЕЛЬ 2: sberbank-ai/ruT5-large\n",
    "print(\"=== НОВАЯ МОДЕЛЬ 2: sberbank-ai/ruT5-large ===\")\n",
    "print(\"Загрузка модели...\")\n",
    "\n",
    "try:\n",
    "    from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "    import torch\n",
    "    \n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"sberbank-ai/ruT5-large\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"sberbank-ai/ruT5-large\")\n",
    "    \n",
    "    # Подготавливаем текст для суммаризации\n",
    "    input_text = \"summarize: \" + text\n",
    "    \n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True, padding=True)\n",
    "    \n",
    "    print(\"Генерирую суммаризацию...\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=150,\n",
    "            min_length=50,\n",
    "            num_beams=4,\n",
    "            repetition_penalty=2.0,\n",
    "            length_penalty=1.0,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    \n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"РЕЗУЛЬТАТ СУММАРИЗАЦИИ:\")\n",
    "    print(\"=\"*50)\n",
    "    print(summary)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Ошибка: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeea3db0-341a-40bf-8a82-c783a7a43daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== НОВАЯ МОДЕЛЬ 3: facebook/bart-large-cnn ===\n",
      "Загрузка модели...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обрабатываю чанк 1/2...\n",
      "Обрабатываю чанк 2/2...\n",
      "\n",
      "==================================================\n",
      "РЕЗУЛЬТАТ СУММАРИЗАЦИИ (английский):\n",
      "==================================================\n",
      "На    математика - это  цифры фор щи  язык, опи  ‘физики’,   ‘’Н. ”‘‘Н’’  “”. ””,   ’. ’ ” Каждая  теорема - это  ще    приближающeе нащ  ‘Матектические’: ‘‘’’. ’”. “”’  ’, ””, ‘,’ ”,\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# НОВАЯ МОДЕЛЬ 3: facebook/bart-large-cnn (ИСПРАВЛЕННАЯ ВЕРСИЯ)\n",
    "print(\"=== НОВАЯ МОДЕЛЬ 3: facebook/bart-large-cnn ===\")\n",
    "print(\"Загрузка модели...\")\n",
    "\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "    \n",
    "    summarizer = pipeline(\"summarization\", \n",
    "                         model=\"facebook/bart-large-cnn\",\n",
    "                         tokenizer=\"facebook/bart-large-cnn\")\n",
    "    \n",
    "    # Уменьшаем размер чанков для английской модели\n",
    "    chunks = chunk_text(text, max_chars=512)\n",
    "    summaries = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Обрабатываю чанк {i+1}/{len(chunks)}...\")\n",
    "        try:\n",
    "            result = summarizer(chunk, \n",
    "                              max_length=120, \n",
    "                              min_length=30, \n",
    "                              do_sample=False,\n",
    "                              truncation=True)\n",
    "            summaries.append(result[0]['summary_text'])\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка в чанке {i+1}: {e}\")\n",
    "            # Пропускаем проблемный чанк\n",
    "            continue\n",
    "    \n",
    "    if summaries:\n",
    "        final_summary = \" \".join(summaries)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"РЕЗУЛЬТАТ СУММАРИЗАЦИИ (английский):\")\n",
    "        print(\"=\"*50)\n",
    "        print(final_summary)\n",
    "        print(\"=\"*50)\n",
    "    else:\n",
    "        print(\"Не удалось сгенерировать суммаризацию\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Ошибка: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f036195-0e94-46b7-b940-53d7629378cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== МОДЕЛЬ: 2KKLabs/Lacia_sum_small_v1 ===\n",
      "Загрузка модели...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Your max_length is set to 120, but your input_length is only 92. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=46)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обрабатываю чанк 1/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 120, but your input_length is only 90. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=45)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обрабатываю чанк 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 120, but your input_length is only 45. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обрабатываю чанк 3/3...\n",
      "\n",
      "==================================================\n",
      "РЕЗУЛЬТАТ СУММАРИЗАЦИИ:\n",
      "==================================================\n",
      "**В этом видео рассказывается о красоте математики.** Автор объясняет, что математика - это не просто сухие цифры и формулы, а удивительный язык, описывающий вселенную. Пример числа Пи - бесконечной десятичной дроби, встречающаяся в самых неожиданных местах, таких как геометрия круга и квантовая физика. **Аментальные математические константы**: Математика учит логическому мышлению, помогает находить закономерности и решать сложные проблемы. Каждая доказанная теорема - это маленькое открытие, приближающее нас к пониманию мира. Автор призывает не бояться математики и подчеркивать ее красоту, подчеркивая ее красоту и увлекательность.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# МОДЕЛЬ: 2KKLabs/Lacia_sum_small_v1\n",
    "print(\"=== МОДЕЛЬ: 2KKLabs/Lacia_sum_small_v1 ===\")\n",
    "print(\"Загрузка модели...\")\n",
    "\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "    \n",
    "    summarizer = pipeline(\n",
    "        \"summarization\",\n",
    "        model=\"2KKLabs/Lacia_sum_small_v1\",\n",
    "        tokenizer=\"2KKLabs/Lacia_sum_small_v1\"\n",
    "    )\n",
    "    \n",
    "    # Разбиваем текст на части\n",
    "    chunks = chunk_text(text, max_chars=400)\n",
    "    summaries = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Обрабатываю чанк {i+1}/{len(chunks)}...\")\n",
    "        try:\n",
    "            result = summarizer(\n",
    "                chunk,\n",
    "                max_length=120,\n",
    "                min_length=30,\n",
    "                do_sample=False,\n",
    "                truncation=True\n",
    "            )\n",
    "            summaries.append(result[0]['summary_text'])\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка в чанке {i+1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if summaries:\n",
    "        final_summary = \" \".join(summaries)\n",
    "        \n",
    "        # Если суммаризации слишком длинные, делаем финальное сокращение\n",
    "        if len(final_summary) > 300:\n",
    "            try:\n",
    "                result = summarizer(\n",
    "                    final_summary,\n",
    "                    max_length=150,\n",
    "                    min_length=50,\n",
    "                    do_sample=False,\n",
    "                    truncation=True\n",
    "                )\n",
    "                final_summary = result[0]['summary_text']\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"РЕЗУЛЬТАТ СУММАРИЗАЦИИ:\")\n",
    "        print(\"=\"*50)\n",
    "        print(final_summary)\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "    else:\n",
    "        print(\"Не удалось сгенерировать суммаризацию\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Ошибка: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8094cc07-ac34-49e3-b15f-b377d8eba05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
